---
title: "P8105_hw3"
author: "Jingwei Ren"
date: "10/12/2018"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

##problem1
First, do some data cleaning:

format the data to use appropriate variable names;
focus on the “Overall Health” topic
include only responses from “Excellent” to “Poor”
organize responses as a factor taking levels ordered from “Excellent” to “Poor”

```{r, clean_up}
brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health" & (response == "Excellent" | response == "Very good" |
                                       response == "Good" | response == "Fair" | 
                                       response == "Poor")) %>% 
  mutate(response = factor(response, level = c("Excellent","Very good", "Good", "Fair", "Poor")))
```

Using this dataset, do or answer the following (commenting on the results of each):

In 2002, which states were observed at 7 locations?
```{r, filter}
brfss %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  summarize(n_location = n_distinct(locationdesc)) %>% 
  filter(n_location == 7)
```
CT,FL and NC were observed at 7 locations.

Make a “spaghetti plot” that shows the number of locations in each state from 2002 to 2010.

```{r, spaghetti_plot}
location_number = brfss %>% 
  group_by(year, locationabbr) %>% 
  summarize(n_location = n_distinct(locationdesc)) 

ggplot(location_number, aes(x = year, y = n_location, color = locationabbr)) +
  geom_line() +
  labs(
    title = "Number of Locations In Each State",
    x = "year",
    y = "number of locations",
    caption = "Data from the p8105.datasets package"
  ) +
  viridis::scale_color_viridis(
    name = "state", 
    discrete = TRUE
  ) 
  
```

The spaghetti plot shows the number of locations in each state from 2002 to 2010. Most states have a constant number of locations from 2002 to 2010. The number of locations has a obvious change in FL from 2006 to 2010. It first increased dramatically and then deceased sharply and finally increased back.

Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.

```{r, table}
brfss %>% 
  filter(year %in% c(2002, 2006, 2010) & 
           response == "Excellent" &
           locationabbr == "NY") %>% 
  group_by(year) %>% 
  summarize(mean_excellent = mean(data_value, na.rm = TRUE), sd_excellent = sd(data_value)) %>% 
  knitr::kable(digits = 2)

```

The table shows the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State in 2002, 2006, and 2010. The mean of proportion of excellent responses is the highest in 2002 and lowest in 2006. 2002 also has the highest standard deviation of proportion of excellent responses, while 2010 has the lowest.


For each year and state, compute the average proportion in each response category (taking the average across locations in a state). Make a five-panel plot that shows, for each response category separately, the distribution of these state-level averages over time.

```{r, proportion}
average_prop = brfss %>% 
  group_by(year, locationabbr, response) %>% 
  summarize(average = mean(data_value, na.rm = TRUE)) 

average_prop %>%
  ggplot(aes(x = year, y = average,color = locationabbr)) +
  geom_line() +
  labs(
    title = "Distribution of State-Level Response Averages Over Time",
    x = "year",
    y = "average proportion of each response",
    caption = "Data from the p8105.datasets package"
  ) +
  facet_wrap(~ response) +
  viridis::scale_color_viridis(
    name = "state", 
    discrete = TRUE
  ) 
```

The five-panel plot shows the distribution of these state-level averages over time. Very good has the highest proportion and poor has the lowest propotion. In each section, the proportion is fairly constant from 2002 to 2010 for almost all states, except that some states had relatively fluctuations in this period.

## problem 2

The goal is to do some exploration of this dataset. To that end, write a short description of the dataset, noting the size and structure of the data, describing some key variables, and giving illstrative examples of observations.

```{r, description}
data("instacart")

instacart %>%
  group_by(order_id) %>%
summarize(n = n())

instacart %>%
  group_by(product_id) %>%
summarize(n = n())

instacart %>% 
  group_by(order_id) %>% 
  summarize( n_product = n_distinct(product_id))

instacart %>%
  group_by(user_id) %>%
summarize(n = n())


```

This dataset has `r nrow(instacart)` rows and `r ncol(instacart)` columns. 
Order_id provides the ID of different orders, and there are total 131209 orders.Product_id provides the ID of different products, and there are total 39123 different products. Add_to_cart_order shows order in which each product was added to cart.Reordered means that 1 if this prodcut has been ordered by this user in the past, 0 otherwise. User_id shows customer identifier.There are total 131209 users, which is same as the amount of order numbers. Order_dow: provides the day of the week on which the order was placed. Order_hour_of_day: shows the hour of the day on which the order was placed. Days_since_prior_order shows days since the last order, capped at 30, NA if order_number=1.Aisle_id provides aisle identifier and department_id provides department identifier.

examples of observations
`r head(instacart, 1) %>% knitr::kable()`

This user with the id:112108 booked an order with the id :1 at 10am on Thursday. This product is Bulgarian Yogurt. Bulgarian Yogurt has been ordered by this user in the past and this is his 4th time order this.  Bulgarian Yogurt has aisle id :120, department id: 16. It belongs to yogurt aisle and dairy eggs department. 


#### do or answer the following (commenting on the results of each):

How many aisles are there, and which aisles are the most items ordered from?
```{r, aisles}
instacart %>%
  group_by(aisle) %>%
summarize(n = n()) %>%
arrange(desc(n))


```
There are total 134 different kinds of aisles. Among them, fresh vegetables has the most items.

Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.

Make a table showing the most popular item in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).




